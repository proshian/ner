# nlp_project

Большинство взаимоотношений между людьми в современном мире фиксируется документально. Такой объем документов, которые существует сейчас уже трудно обрабатывать вручную. 
Целью работы является программная реализация алгоритма выявления сущностей из документов муниципальных структур при помощи глубокого обучения в целях сокращения времени, которое затрачивается на обработку документов. 
В работе представлена реализация алгоритма  CNN-LSTM для решения поставленной задачи.  
В качестве датасета для обучения выбран документов Министерства экономического развития Российской Федерации. В результате выполнения проекта получены удовлетворительные результаты работы программ.

Архитектура CNN LSTM предполагает использование слоев сверточной нейронной сети (CNN) для извлечения признаков во входных данных в сочетании с LSTM для поддержки прогнозирования последовательности.

LSTM CNN были разработаны для задач визуального прогнозирования временных рядов и применения генерирования текстовых описаний из последовательностей изображений (например, видео). В частности, проблемы:
Признание деятельности: Создание текстового описания действия, демонстрируемого в последовательности изображений.
Описание изображения: Генерация текстового описания одного изображения.
Описание видео: Генерирование текстового описания последовательности изображений.

[CNN LSTMs]-это класс моделей, которые имеют как пространственную, так и временную глубину и обладают гибкостью, которую можно применять для решения различных задач, связанных с последовательным вводом и выводом.

![image](https://github.com/u-tain/nlp_project/assets/117383235/a2653e7e-5762-4efe-8767-0d6834b10187)

LSTM (long short-term memory, дословно (долгая краткосрочная память)) — тип рекуррентной нейронной сети, способный обучаться долгосрочным зависимостям. 

LSTM были представлены в работе [Hochreiter & Schmidhuber (1997)]. Эта архитектура была создана для устранения проблемы долгострочных зависимостей. Пример: Я вырос во Франции … Я свободно говорю на французском.

![image](https://github.com/u-tain/nlp_project/assets/117383235/4f1a0b1b-3d83-46ca-a015-9914463f6abc)

Все рекуррентные нейронные сети имеют форму цепочки повторяющихся модулей нейронной сети. В простой сети там находится один модуль tanh, в рекурентной же находится 4 модуля.

![image](https://github.com/u-tain/nlp_project/assets/117383235/e6051ca5-3721-4220-864d-233607e6b466)

Ключевым понятием LSTM является состояние ячейки: горизонтальная линия, проходящая через верхнюю часть диаграммы. В LSTM уменьшает или увеличивает количество информации в состоянии ячейки, в зависимости от потребностей. Для этого используются тщательно настраиваемые структуры, называемые гейтами. Гейт — это «ворота», пропускающие или не пропускающие информацию. Гейты состоят из сигмовидного слоя нейронной сети и операции поточечного умножения. Соотвественно каждая операция изменяет состояние ячейки в зависимости от нужд. Приведенный пример являет собой классическую lstm однако есть определенные модификации которые добавляю дополнительные операции в каждую ячейку.

